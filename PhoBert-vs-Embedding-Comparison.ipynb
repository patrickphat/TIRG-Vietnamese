{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import img_text_composition_models\n",
    "from enum import Enum\n",
    "import datasets\n",
    "import torchvision\n",
    "import torch\n",
    "from main import load_dataset, create_model_and_optimizer\n",
    "import test_retrieval\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from utils.FilePickling import pkl_save, pkl_load\n",
    "import numpy as np\n",
    "from test_retrieval import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_stats_word(testset, error_ids, words_list):\n",
    "    \"\"\"\n",
    "    Calculate p(S=wrong|word in S)\n",
    "    \"\"\"\n",
    "    \n",
    "    test_queries = testset.get_test_queries()\n",
    "    \n",
    "    dict_verb_wrong = {word:0 for word in words_list}\n",
    "    dict_all_verb = {word:0 for word in words_list}\n",
    "    \n",
    "    # Count all words\n",
    "    for i, query in enumerate(test_queries):\n",
    "        that_str = query[\"mod\"][\"str\"] \n",
    "        words = that_str.split()\n",
    "        \n",
    "        # Count all words\n",
    "        for r_word in words_list:\n",
    "            if r_word in words:\n",
    "                dict_all_verb[r_word] += 1\n",
    "                \n",
    "        # Count error words\n",
    "        if i in error_ids:\n",
    "            for r_word in words_list:\n",
    "                if r_word in words:\n",
    "                    try:\n",
    "                        dict_verb_wrong[r_word] += 1\n",
    "                    except:\n",
    "                        dict_verb_wrong[r_word] = 1\n",
    "            \n",
    "    stats_dict = {}\n",
    "    \n",
    "    for word in words_list:\n",
    "        stats_dict[word] = dict_verb_wrong[word] / dict_all_verb[word]\n",
    "        \n",
    "       \n",
    "\n",
    "        \n",
    "    return stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset  css3d\n",
      "trainset size: 19012\n",
      "testset size: 19057\n",
      "Reading dataset  css3d\n",
      "trainset size: 19012\n",
      "testset size: 19057\n",
      "Creating model and optimizer for tirg\n",
      "Pretrained model from runs/Dec17_11-17-51_ai-servers-1tirg_css-vn-v2-segmenter/best_checkpoint.pth\n",
      "Creating model and optimizer for tirg_phobert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model from runs/Dec12_14-57-59_ai-servers-1tirgphobert_css-vn-v2-segmenter/latest_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "class css_base_dataset_opt:\n",
    "    def __init__(self):\n",
    "        self.dataset = \"css3d\"\n",
    "        self.dataset_path = \"../data/CSSDataset/CSS-vn-v2-segmenter.json\" \n",
    "\n",
    "class css_augmented_dataset_opt:\n",
    "    def __init__(self):\n",
    "        self.dataset = \"css3d\"\n",
    "        self.dataset_path = \"../data/CSSDataset/CSS-vn-augmented-segmenter-v2.json\" \n",
    "        \n",
    "class phobert_model_opt:\n",
    "    def __init__(self):\n",
    "        self.dataset = \"css3d\"\n",
    "        self.model = \"tirg_phobert\" \n",
    "        self.loss = \"soft_triplet\" \n",
    "        self.comment = \"tirg_phobert\"\n",
    "        self.embed_dim = 512\n",
    "        self.learning_rate = 1e-2\n",
    "        self.weight_decay = 1e-6 \n",
    "        self.f = \"\"\n",
    "        self.learning_rate_decay_frequency = 99999999\n",
    "        self.batch_size = 32\n",
    "        self.num_epochs = 100\n",
    "        self.n_epochs_valudations = 5\n",
    "        self.loader_num_workers = 4\n",
    "        self.pretrained_weights = \"runs/Dec12_14-57-59_ai-servers-1tirgphobert_css-vn-v2-segmenter/latest_checkpoint.pth\"\n",
    "\n",
    "class base_model_opt:\n",
    "    def __init__(self):\n",
    "        self.dataset = \"css3d\"\n",
    "        self.model = \"tirg\" \n",
    "        self.loss = \"soft_triplet\" \n",
    "        self.comment = \"tirg_base\"\n",
    "        self.embed_dim = 512\n",
    "        self.learning_rate = 1e-2\n",
    "        self.weight_decay = 1e-6 \n",
    "        self.f = \"\"\n",
    "        self.learning_rate_decay_frequency = 99999999\n",
    "        self.batch_size = 32\n",
    "        self.num_epochs = 100\n",
    "        self.n_epochs_valudations = 5\n",
    "        self.loader_num_workers = 4\n",
    "        self.pretrained_weights = \"runs/Dec17_11-17-51_ai-servers-1tirg_css-vn-v2-segmenter/best_checkpoint.pth\"        \n",
    "\n",
    "trainset_base, testset_base = load_dataset(css_base_dataset_opt())\n",
    "_, testset_augmented = load_dataset(css_augmented_dataset_opt())\n",
    "texts = [t for t in trainset_base.get_all_texts()]\n",
    "\n",
    "base_model, _ = create_model_and_optimizer(base_model_opt(), texts)\n",
    "phobert_model, _ = create_model_and_optimizer(phobert_model_opt(), texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18057/18057 [01:01<00:00, 293.58it/s]\n",
      "100%|██████████| 19057/19057 [00:58<00:00, 325.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('recall_top1_correct_composition', 0.7663509996123387),\n",
       " ('recall_top5_correct_composition', 0.9441767735504236),\n",
       " ('recall_top10_correct_composition', 0.968101013457385),\n",
       " ('recall_top50_correct_composition', 0.9919698731793765),\n",
       " ('recall_top100_correct_composition', 0.9951265437226561)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, error_ids = test(phobert_model_opt(), phobert_model, testset_base)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dict_wrong_verb(testset_base, error_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18057/18057 [01:05<00:00, 276.58it/s]\n",
      "100%|██████████| 19057/19057 [00:59<00:00, 322.16it/s]\n"
     ]
    }
   ],
   "source": [
    "out, error_ids = test(phobert_model_opt(), phobert_model, testset_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bé': 0.20936395759717313, 'to': 0.23345049794961922}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = error_stats_word(testset_augmented, error_ids, words_list = [\"bé\", \"to\"])\n",
    "report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7665"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(1 - 0.23345049794961922,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_base.get_all_texts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18057/18057 [00:55<00:00, 327.40it/s]\n",
      "100%|██████████| 19057/19057 [00:56<00:00, 334.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('recall_top1_correct_composition', 0.7818574514038877),\n",
       " ('recall_top5_correct_composition', 0.9499916929722545),\n",
       " ('recall_top10_correct_composition', 0.9720883867752118),\n",
       " ('recall_top50_correct_composition', 0.9930774768787728),\n",
       " ('recall_top100_correct_composition', 0.9962895276070222)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report, error_ids = test(base_model_opt(), base_model, testset_base)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nhỏ': 0.19081272084805653, 'lớn': 0.21719390743995312}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_stats_word(testset_base, error_ids, words_list = [\"nhỏ\", \"lớn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18057/18057 [00:54<00:00, 332.90it/s]\n",
      "100%|██████████| 19057/19057 [00:56<00:00, 337.62it/s]\n"
     ]
    }
   ],
   "source": [
    "report, error_ids = test(base_model_opt(), base_model, testset_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_augmented.get_test_queries()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bé': 0.5742049469964664, 'to': 0.5694200351493849}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_stats_word(testset_augmented, error_ids, words_list = [\"bé\", \"to\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4306"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(1- 0.5694200351493849, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_prob(n_babies):\n",
    "    prob = 1 \n",
    "    for i in range(n_babies):\n",
    "        prob *= (365-i)/365\n",
    "    return 1-prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.568699703969464"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_prob(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0273972602739726"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "365/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
